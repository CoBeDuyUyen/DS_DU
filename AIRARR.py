# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/190MZTAg51C1DSCUclPKtYqlfoaIY53H9

# 1. Introduction:
This report will have us to predict how late flights will be. A flight only counts as late if it is more than 30 minutes late.
Firstly, we will import some libraries to support the code.
"""

!pip install nbconvert

!jupyter nbconvert --to html Untitled0.ipynb

!pip install PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

downloaded = drive.CreateFile({'id':"1cx9DWer_kdi7NZ85RKoeO03OvOKfRLtH"})   # replace the id with id of file you want to access
downloaded.GetContentFile('AA.csv')

import pandas as pd
import plotly.express as px
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

"""# 2. Exploring the data:"""

data = pd.read_csv("AA.csv")
data.head(10)

data.shape

data.dtypes

display(data.isnull().sum()/len(data))

"""We will remove features which have a high rate null-value (>70%)."""

data.drop('CancellationCode', inplace=True, axis = 1) 
data.drop('CarrierDelay', inplace=True, axis = 1) 
data.drop('WeatherDelay', inplace=True, axis = 1)
data.drop('NASDelay', inplace=True, axis = 1) 
data.drop('SecurityDelay', inplace=True, axis = 1) 
data.drop('LateAircraftDelay', inplace=True, axis = 1)

display(data.isnull().sum()/len(data))

#xoa feature co duy nhat mot gia tri
for column in data.columns: 
    if data[column].nunique() == 1:
        data.drop(column, inplace = True, axis = 1)
data.shape

import seaborn as sns
for column in data.columns:
    if data[column].dtypes != object:
        ax = sns.boxplot(x=data[column])
        plt.show()

cont_col = []
for column in data.columns:
    if data[column].dtypes != object:
        cont_col.append(column)
plt.figure(figsize=(20, 40))

for i, column in enumerate(cont_col, 1):
    plt.subplot(9, 2, i)
    data[column].hist(bins=35, color='blue', alpha=0.6)
    plt.xlabel(column)

"""Remove 'Diverted' and 'Cancelled' from the data set."""

data.drop('Diverted', inplace=True, axis = 1) 
data.drop('Cancelled', inplace=True, axis = 1)
display(data.isnull().sum()/len(data))

"""Replace null-value in 'TaxiIn' and 'TaxiOut' by mode value."""

data['TaxiIn'] = data['TaxiIn'].fillna(data['TaxiIn'].mode()[0])
data['TaxiOut'] = data['TaxiOut'].fillna(data['TaxiOut'].mode()[0])
display(data.isnull().sum()/len(data))

"""Then we don't have null value any more."""

data = data.dropna()
display(data.isnull().sum()/len(data))

"""## Check the correlation"""

plt.figure(figsize=(14,3))
plt.figure(figsize=(15,10))
correlations = data.corr()
sns.heatmap(round(correlations,2), cmap='RdBu', annot=True, 
            annot_kws={"size": 7}, vmin=-1, vmax=1);

data.drop('AirTime', inplace = True, axis = 1)
data.drop('ActualElapsedTime', inplace = True, axis = 1)
data.drop('Distance', inplace = True, axis = 1)
data.drop('TaxiOut', inplace = True, axis = 1)
plt.figure(figsize=(14,3))
plt.figure(figsize=(15,10))
correlations = data.corr()
sns.heatmap(round(correlations,2), cmap='RdBu', annot=True, 
            annot_kws={"size": 7}, vmin=-1, vmax=1);

fig = px.histogram(data, x='ArrDelay')
fig.show()

data.drop('DepTime', inplace = True, axis = 1)
data.drop('ArrTime', inplace = True, axis = 1)

"""normal distribution, không cần phải chuyển nữa"""

data.describe(percentiles = [.1, .25, .5, .75, .97, .99])

"""## ANOVA"""

import statsmodels.api as sm
from statsmodels.formula.api import ols
iris_lm=ols('ArrDelay ~  Month + DayofMonth + DayOfWeek + CRSDepTime + FlightNum + CRSElapsedTime + DepDelay + TaxiIn', data=data).fit() #Specify C for Categorical
sm.stats.anova_lm(iris_lm, typ=2)

"""We can see that 'FlightNum', 'CRSElapsedTime', 'DepDelay', 'TaxiIn' affect strongly to 'ArrDelay'

# Without PCA
## Linear Regression
"""

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_predict
LR = LinearRegression() 
all_Data = []
all_Data = data.drop(["DepDelay", "ArrDelay", "UniqueCarrier", "TailNum", "Origin", "Dest"],axis=1)
X = all_Data
y = data["ArrDelay"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
LR.fit(X_train,y_train)
y_predict = LR.predict(X_test)
print("Mean squared error is: %.4f"%mean_squared_error(y_test, y_predict))

from sklearn.model_selection import cross_validate
cv = cross_validate(LR, X, y, cv = 5)
scoring = {'R_squared':'r2', 'MSE':'neg_mean_squared_error'}
cv = cross_validate(LR, X, y, cv = 5, scoring = scoring)
r2 = cv['test_R_squared'].mean()
mse = abs(cv['test_MSE'].mean())
rmse = np.sqrt(mse)
print('r2: ', r2)
print('rmse: ', rmse)

predicted = cross_val_predict(LR, X.values, y.values, cv=10)
fig, ax = plt.subplots()
ax.scatter(y, predicted)
ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)
ax.set_xlabel('Measured')
ax.set_ylabel('Predicted')
plt.show()

"""## Logistic Regression"""

from sklearn.linear_model import LogisticRegression
LOR = LogisticRegression(solver='liblinear', random_state=0)
data.insert(0,'Lated', 0) 
data.loc[(data.ArrDelay <= 30), 'Lated'] = 0
data.loc[(data.ArrDelay > 30), 'Lated'] = 1
y = np.array(data['Lated'])

X = all_Data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=25)
LOR.fit(X_train, y_train)
LOR.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
y_pred = LOR.predict(X_test)
confusion_matrix = confusion_matrix(y_test, y_pred)
confusion_matrix

#from sklearn.model_selection import cross_val_score
#print(cross_val_score(LOR, X, y, cv=10, scoring='accuracy').mean())

from sklearn.metrics import plot_roc_curve
LOR_disp = plot_roc_curve(LOR, X_test, y_test)
plt.show()

"""## Naive Bayes

"""

from sklearn.naive_bayes import GaussianNB
GNB = GaussianNB()
GNB.fit(X_train, y_train)
GNB.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
y_pred = GNB.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm

from sklearn.model_selection import cross_val_score
print(cross_val_score(GNB, X, y, cv=10, scoring='accuracy').mean())

from sklearn.metrics import plot_roc_curve
GNB_disp = plot_roc_curve(GNB, X_test, y_test)
plt.show()

"""## Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
DT = DecisionTreeClassifier()
DT.fit(X_train, y_train)
DT.score(X_test, y_test)

print("Depth: ", DT.get_depth())
print("Leaves: ", DT.get_n_leaves())

from sklearn.metrics import confusion_matrix
y_pred = DT.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm

from sklearn.model_selection import cross_val_score
print(cross_val_score(DT, X, y, cv=10, scoring='accuracy').mean())

from sklearn.metrics import plot_roc_curve
DT_disp = plot_roc_curve(DT, X_test, y_test)
plt.show()

"""## Random Forest"""

from sklearn.ensemble import RandomForestClassifier
RF = RandomForestClassifier()
RF.fit(X_train, y_train)
RF.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
y_pred = RF.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm

#from sklearn.model_selection import cross_val_score
#print(cross_val_score(RF, X, y, cv=10, scoring='accuracy').mean())

from sklearn.metrics import plot_roc_curve
RF_disp = plot_roc_curve(RF, X_test, y_test)
plt.show()

"""## Gradient Boosting"""

from sklearn.ensemble import GradientBoostingClassifier
GB = GradientBoostingClassifier(random_state=0)
GB.fit(X_train, y_train)
GB.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
y_pred = GB.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm

from sklearn.metrics import plot_roc_curve
GB_disp = plot_roc_curve(GB, X_test, y_test)
plt.show()

"""## SVM"""

from sklearn.svm import LinearSVC
SVM = LinearSVC().fit(X_train, y_train)
SVM.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
y_pred = SVM.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm

from sklearn.metrics import plot_roc_curve
svc_disp = plot_roc_curve(SVM, X_test, y_test)
plt.show()

"""## AUC """

lor = plot_roc_curve(LOR, X_test, y_test)
gnb = plot_roc_curve(GNB, X_test, y_test, ax=lor.ax_)
dt = plot_roc_curve(DT, X_test, y_test, ax=gnb.ax_)
rf = plot_roc_curve(RF, X_test, y_test, ax=dt.ax_)
gb = plot_roc_curve(GB, X_test, y_test, ax=rf.ax_)
SvM = plot_roc_curve(SVM, X_test, y_test, ax=gb.ax_)
plt.show()

"""# With PCA"""

from sklearn.feature_selection import SelectKBest, f_classif
X_new = SelectKBest(f_classif, k=5).fit_transform(X, y)
X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size = .3, random_state=25)

"""## Logistic Regression"""

LOR.fit(X_train, y_train)
LOR.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
y_pred = LOR.predict(X_test)
confusion_matrix = confusion_matrix(y_test, y_pred)
confusion_matrix

from sklearn.metrics import plot_roc_curve
LOR_disp = plot_roc_curve(LOR, X_test, y_test)
plt.show()

"""## Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
GNB = GaussianNB()
GNB.fit(X_train, y_train)
GNB.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
y_pred = GNB.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm

from sklearn.metrics import plot_roc_curve
GNB_disp = plot_roc_curve(GNB, X_test, y_test)
plt.show()

"""## Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
DT = DecisionTreeClassifier()
DT.fit(X_train, y_train)
DT.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
y_pred = DT.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm

from sklearn.metrics import plot_roc_curve
DT_disp = plot_roc_curve(DT, X_test, y_test)
plt.show()

"""## Random Forest"""

from sklearn.ensemble import RandomForestClassifier
RF = RandomForestClassifier()
RF.fit(X_train, y_train)
RF.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
y_pred = RF.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm

from sklearn.metrics import plot_roc_curve
RF_disp = plot_roc_curve(RF, X_test, y_test)
plt.show()

"""## Gradient Boosting"""

from sklearn.ensemble import GradientBoostingClassifier
GB = GradientBoostingClassifier(random_state=0)
GB.fit(X_train, y_train)
GB.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
y_pred = GB.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm

from sklearn.metrics import plot_roc_curve
GB_disp = plot_roc_curve(GB, X_test, y_test)
plt.show()

"""## SVM"""

from sklearn.svm import LinearSVC
SVM = LinearSVC().fit(X_train, y_train)
SVM.score(X_test, y_test)

from sklearn.metrics import confusion_matrix
y_pred = SVM.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
cm

from sklearn.metrics import plot_roc_curve
svc_disp = plot_roc_curve(SVM, X_test, y_test)
plt.show()

"""## AUC"""

lor = plot_roc_curve(LOR, X_test, y_test)
gnb = plot_roc_curve(GNB, X_test, y_test, ax=lor.ax_)
dt = plot_roc_curve(DT, X_test, y_test, ax=gnb.ax_)
rf = plot_roc_curve(RF, X_test, y_test, ax=dt.ax_)
gb = plot_roc_curve(GB, X_test, y_test, ax=rf.ax_)
SvM = plot_roc_curve(SVM, X_test, y_test, ax=gb.ax_)
plt.show()